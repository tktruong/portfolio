{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest Cover Type Prediction\n",
    "\n",
    "Based on: https://www.kaggle.com/c/forest-cover-type-prediction\n",
    "\n",
    "This notebook analyzes the use of Decision Tree and Random Forest modeling to predict forest cover type in Roosevelt National Forest in northern Colorado. The goal is to predict which of 7 cover types exists in a 30 m x 30 m plot based on various geographic and environmental variables. Exploratory Data Analysis (EDA) of the training data was performed in collaboration with my teammates in a separate notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "1.14.3\n",
      "0.23.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import copy\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Distribution:\n",
      " Cover_Type\n",
      "1    1724\n",
      "2    1726\n",
      "3    1737\n",
      "4    1705\n",
      "5    1735\n",
      "6    1732\n",
      "7    1737\n",
      "Name: Cover_Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Load CSV into Dataframe\n",
    "train = pd.read_csv('train.csv', index_col = 0)\n",
    "\n",
    "### Split the data into train, dev, test with a 80-10-10 ratio\n",
    "np.random.seed(0) # random seed so we get the same shuffle\n",
    "\n",
    "X = train.drop('Cover_Type', axis = 1)\n",
    "Y = train['Cover_Type']\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0])) # shuffle the data\n",
    "X, Y = X.iloc[shuffle], Y.iloc[shuffle]\n",
    "\n",
    "train_data, train_labels = X[:12096], Y[:12096]        # the train set\n",
    "dev_data, dev_labels = X[12096:13608], Y[12096:13608]  # the dev set\n",
    "test_data, test_labels = X[13608:], Y[13608:]          # the test set\n",
    "print(\"Training Label Distribution:\\n\", train_labels.groupby(train_labels).size())  # check label distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree, Random Forest, & Boosting Modeling\n",
    "\n",
    "For replicability of the results, we used random_state = 0 for all of our Decision Tree and Random Forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepcopy dev_data, test_data\n",
    "dt_train = copy.deepcopy(train_data)\n",
    "dt_dev = copy.deepcopy(dev_data)\n",
    "dt_test = copy.deepcopy(test_data)\n",
    "\n",
    "# keeping track of experiments and accuracies\n",
    "\n",
    "dt_accuracies = []\n",
    "dt_experiments = []\n",
    "rf_accuracies = []\n",
    "rf_experiments = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(model, train_data, train_labels, dev_data, dev_labels, metrics = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes a custom model and fits the train data and labels\n",
    "    Prints classification report, confusion, matrix, and accuracy\n",
    "    Returns accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    model.fit(train_data, train_labels)\n",
    "    dtree_pred = model.predict(dev_data)\n",
    "    \n",
    "    if metrics == True:\n",
    "        print(classification_report(dev_labels, dtree_pred))\n",
    "        print(confusion_matrix(dev_labels, dtree_pred))\n",
    "        print(\"\\naccuracy:\", np.mean(dev_labels == dtree_pred))\n",
    "    \n",
    "    return np.mean(dev_labels == dtree_pred)\n",
    "\n",
    "def importance_table(model, data, sort = True):\n",
    "    \"\"\" By default, create dataframe (descending sort) of feature importances of decision tree or random forest model \"\"\"\n",
    "    \n",
    "    table = pd.DataFrame({'importance':model.feature_importances_}, index = data.columns)\n",
    "    \n",
    "    if sort == True:\n",
    "        return table.sort_values(by = 'importance', axis = 0, ascending = False)\n",
    "    elif sort == False:\n",
    "        return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "### Basic Decision Tree Model\n",
    "\n",
    "First, we established a baseline with a simple Decision Tree model, changing the criterion to entropy. This resulted in 79.23% accuracy on the development data. From the confusion matrix, we saw that the model has the most trouble with cover types 1, 2, 3, and 6. In examining feature importance of the baseline model, we saw that Elevation, Horizontal Distance to Roadways, Horizontal Distance to Fire Points, Horizontal Distance to Hydrology were ranked the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.63      0.66       216\n",
      "           2       0.65      0.58      0.62       226\n",
      "           3       0.76      0.73      0.75       203\n",
      "           4       0.92      0.95      0.93       243\n",
      "           5       0.84      0.93      0.88       198\n",
      "           6       0.78      0.78      0.78       222\n",
      "           7       0.87      0.95      0.91       204\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1512\n",
      "   macro avg       0.79      0.79      0.79      1512\n",
      "weighted avg       0.79      0.79      0.79      1512\n",
      "\n",
      "[[137  50   1   0   4   1  23]\n",
      " [ 54 132   3   1  24   7   5]\n",
      " [  0   4 149   9   4  37   0]\n",
      " [  0   0  10 230   0   3   0]\n",
      " [  2   7   3   0 184   1   1]\n",
      " [  0   8  30   9   2 173   0]\n",
      " [  8   1   0   0   2   0 193]]\n",
      "\n",
      "accuracy: 0.7923280423280423\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>0.551508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>0.074367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>0.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>0.053318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <td>0.046529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0.026441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>0.026102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>0.024384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area1</th>\n",
       "      <td>0.022788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <td>0.022064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>0.015115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type3</th>\n",
       "      <td>0.010435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <td>0.009432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type10</th>\n",
       "      <td>0.008871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type4</th>\n",
       "      <td>0.005386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type39</th>\n",
       "      <td>0.004224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type29</th>\n",
       "      <td>0.003109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type2</th>\n",
       "      <td>0.003102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type33</th>\n",
       "      <td>0.003051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type23</th>\n",
       "      <td>0.002960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type38</th>\n",
       "      <td>0.002266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type32</th>\n",
       "      <td>0.002256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type12</th>\n",
       "      <td>0.002186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type13</th>\n",
       "      <td>0.002002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type17</th>\n",
       "      <td>0.001883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type11</th>\n",
       "      <td>0.001746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type20</th>\n",
       "      <td>0.001742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type30</th>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type6</th>\n",
       "      <td>0.001582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type40</th>\n",
       "      <td>0.001330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type31</th>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type24</th>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type22</th>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type35</th>\n",
       "      <td>0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type1</th>\n",
       "      <td>0.000594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area4</th>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type16</th>\n",
       "      <td>0.000377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type14</th>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type27</th>\n",
       "      <td>0.000319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type26</th>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type21</th>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type18</th>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type9</th>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type5</th>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type25</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type28</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type34</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type15</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type36</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type37</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type19</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    importance\n",
       "Elevation                             0.551508\n",
       "Horizontal_Distance_To_Roadways       0.074367\n",
       "Horizontal_Distance_To_Fire_Points    0.060600\n",
       "Horizontal_Distance_To_Hydrology      0.053318\n",
       "Hillshade_9am                         0.046529\n",
       "Vertical_Distance_To_Hydrology        0.026441\n",
       "Hillshade_Noon                        0.026102\n",
       "Aspect                                0.024384\n",
       "Wilderness_Area1                      0.022788\n",
       "Hillshade_3pm                         0.022064\n",
       "Slope                                 0.015115\n",
       "Soil_Type3                            0.010435\n",
       "Wilderness_Area3                      0.009432\n",
       "Soil_Type10                           0.008871\n",
       "Soil_Type4                            0.005386\n",
       "Soil_Type39                           0.004224\n",
       "Soil_Type29                           0.003109\n",
       "Soil_Type2                            0.003102\n",
       "Soil_Type33                           0.003051\n",
       "Soil_Type23                           0.002960\n",
       "Soil_Type38                           0.002266\n",
       "Soil_Type32                           0.002256\n",
       "Soil_Type12                           0.002186\n",
       "Soil_Type13                           0.002002\n",
       "Soil_Type17                           0.001883\n",
       "Soil_Type11                           0.001746\n",
       "Soil_Type20                           0.001742\n",
       "Soil_Type30                           0.001736\n",
       "Soil_Type6                            0.001582\n",
       "Soil_Type40                           0.001330\n",
       "Soil_Type31                           0.001189\n",
       "Soil_Type24                           0.001127\n",
       "Soil_Type22                           0.001089\n",
       "Soil_Type35                           0.001025\n",
       "Soil_Type1                            0.000594\n",
       "Wilderness_Area4                      0.000437\n",
       "Soil_Type16                           0.000377\n",
       "Soil_Type14                           0.000369\n",
       "Soil_Type27                           0.000319\n",
       "Soil_Type26                           0.000248\n",
       "Soil_Type21                           0.000171\n",
       "Wilderness_Area2                      0.000148\n",
       "Soil_Type18                           0.000142\n",
       "Soil_Type9                            0.000138\n",
       "Soil_Type5                            0.000115\n",
       "Soil_Type25                           0.000000\n",
       "Soil_Type28                           0.000000\n",
       "Soil_Type7                            0.000000\n",
       "Soil_Type34                           0.000000\n",
       "Soil_Type15                           0.000000\n",
       "Soil_Type36                           0.000000\n",
       "Soil_Type37                           0.000000\n",
       "Soil_Type19                           0.000000\n",
       "Soil_Type8                            0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specifying entropy, default is gini\n",
    "dtree1 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "dt_accuracies.append(model_performance(dtree1, dt_train, train_labels, dt_dev, dev_labels))\n",
    "dt_experiments.append('Basic Decision Tree')\n",
    "importance_table(dtree1, dt_train, sort = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: Optimizing max_depth parameter\n",
    "\n",
    "After running the baseline Decision Tree model, we sought to optimize parameters that could improve performance and reduce overfitting. First, we looked at the max_depth parameter, which controls the maximum depth of the tree that is generated. Through GridSearchCV, we found that 24 is the optimal max_depth, which \"prunes\" our Decision Tree by 30 levels. In using a model with max_depth = 24, we saw slight improvement in accuracy from 79.23% to 79.70%. At the same time, the feature importances ranking looked similar to that of the baseline model.\n",
    "\n",
    "### Decision Tree: Optimizing max_features\n",
    "\n",
    "Next, we examined the max_features parameter, which refers to the maximum number of features to consider when looking for the best split. We found that 40 features was the optimal setting and this yielded an accuracy of 79.56%. Overall, in terms of accuracy, precision, recall, and F-1 scores, this version was comparable to the model with max_depth = 24. However, this model has more nodes than the latter, so we opted for the more parsimonious model given that the comparable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__max_depth': 24}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.65      0.67       216\n",
      "           2       0.68      0.60      0.63       226\n",
      "           3       0.76      0.74      0.75       203\n",
      "           4       0.92      0.95      0.93       243\n",
      "           5       0.84      0.93      0.88       198\n",
      "           6       0.78      0.78      0.78       222\n",
      "           7       0.87      0.95      0.91       204\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1512\n",
      "   macro avg       0.79      0.80      0.79      1512\n",
      "weighted avg       0.79      0.80      0.79      1512\n",
      "\n",
      "[[140  47   1   0   4   1  23]\n",
      " [ 49 135   4   1  24   8   5]\n",
      " [  0   3 150   9   4  37   0]\n",
      " [  0   0  10 230   0   3   0]\n",
      " [  3   6   3   0 184   1   1]\n",
      " [  0   8  30   9   2 173   0]\n",
      " [ 10   1   0   0   0   0 193]]\n",
      "\n",
      "accuracy: 0.796957671957672\n",
      "{'classifier__max_features': 40}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.66      0.66       216\n",
      "           2       0.69      0.59      0.64       226\n",
      "           3       0.76      0.76      0.76       203\n",
      "           4       0.93      0.94      0.93       243\n",
      "           5       0.84      0.95      0.89       198\n",
      "           6       0.77      0.77      0.77       222\n",
      "           7       0.88      0.91      0.89       204\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1512\n",
      "   macro avg       0.79      0.80      0.79      1512\n",
      "weighted avg       0.79      0.80      0.79      1512\n",
      "\n",
      "[[142  49   0   0   5   1  19]\n",
      " [ 52 134   3   1  23   7   6]\n",
      " [  0   1 154   9   2  37   0]\n",
      " [  0   0  11 228   0   4   0]\n",
      " [  2   5   2   0 188   1   0]\n",
      " [  0   5  33   7   5 172   0]\n",
      " [ 16   1   0   0   2   0 185]]\n",
      "\n",
      "accuracy: 0.7956349206349206\n"
     ]
    }
   ],
   "source": [
    "# this can take 2-3 mins to run\n",
    "dtpl = Pipeline([('classifier', dtree1)])\n",
    "\n",
    "param_grid = dict(classifier__max_depth = [n for n in range(1, (dt_train.shape[1] + 1))])\n",
    "\n",
    "dtgs = GridSearchCV(dtpl, param_grid, iid = True, refit = True, cv=5, return_train_score=True).fit(dt_train, train_labels)\n",
    "print(dtgs.best_params_)\n",
    "\n",
    "dtree2 = DecisionTreeClassifier(criterion = 'entropy', max_depth = 24, random_state = 0)\n",
    "dt_accuracies.append(model_performance(dtree2, dt_train, train_labels, dt_dev, dev_labels))\n",
    "dt_experiments.append('Decision Tree with max_depth = 24')\n",
    "\n",
    "param_grid = dict(classifier__max_features = [n for n in range(1, (dt_train.shape[1] + 1))])\n",
    "\n",
    "dtgs = GridSearchCV(dtpl, param_grid, iid = True, refit = True, cv=5, return_train_score=True).fit(dt_train, train_labels)\n",
    "print(dtgs.best_params_)\n",
    "\n",
    "dtree3 = DecisionTreeClassifier(criterion = 'entropy', max_features = 40, random_state = 0)\n",
    "dt_accuracies.append(model_performance(dtree3, dt_train, train_labels, dt_dev, dev_labels))\n",
    "dt_experiments.append('Decision Tree with max_features = 40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: Optimizing min_samples_split & min_samples_leaf\n",
    "\n",
    "Next, we respectively optimized for min_samples_split, which refers to the minimum number of samples to split an internal node, and  min_samples_leaf, which refers to the minimum number of samples to be in a leaf node. From this optimizations, we found that percentages closest to 0 for both min_samples_split and min_samples_leaf achieved the best results. For example, min_samples_split to 0.01 pruned the tree back too far so accuracy was reduced to 74.21%. This version had only 411 nodes compared to approximately 3233 for the baseline and optimized max_depth trees respectively. With min_samples_split = 0.001, the accuracy was still lower than that of the baseline model. Similarly, with min_samples_leaf = 0.001, the accuracy achieved was 76.85%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__min_samples_split': 0.001}\n",
      "{'classifier__min_samples_leaf': 0.001}\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(classifier__min_samples_split = [n for n in np.arange(0.001, 0.01, 0.01)])\n",
    "\n",
    "dtgs = GridSearchCV(dtpl, param_grid, iid = True, refit = True, cv=5, return_train_score=True).fit(dt_train, train_labels)\n",
    "print(dtgs.best_params_)\n",
    "\n",
    "dtree4 = DecisionTreeClassifier(criterion = 'entropy', min_samples_split = 0.001, random_state = 0)\n",
    "dt_accuracies.append(model_performance(dtree4, dt_train, train_labels, dt_dev, dev_labels, metrics = False))\n",
    "dt_experiments.append('Decision Tree with min_samples_split = 0.001')\n",
    "\n",
    "param_grid = dict(classifier__min_samples_leaf = [n for n in np.arange(0.001, 0.01, 0.002)])\n",
    "\n",
    "dtgs = GridSearchCV(dtpl, param_grid, iid = True, refit = True, cv=5, return_train_score=True).fit(dt_train, train_labels)\n",
    "print(dtgs.best_params_)\n",
    "\n",
    "dtree5 = DecisionTreeClassifier(criterion = 'entropy', min_samples_leaf = 0.001, random_state = 0)\n",
    "dt_accuracies.append(model_performance(dtree5, dt_train, train_labels, dt_dev, dev_labels, metrics = False))\n",
    "dt_experiments.append('Decision Tree with min_samples_leaf = 0.001')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Modeling\n",
    "\n",
    "### Random Forest: Optimizing n_estimators\n",
    "\n",
    "To get a sense of the appropriate parameter grid, we initially tried 10, 1000, and 1500 trees respectively to establish a baseline and determine an appropriate range for the parameter grid. With 10 trees, the model had an accuracy of approximately 82%. The models with 1000 and 1500 trees respectively had accuracies around 86%. Given that the higher the number of trees used in Random Forest, the longer it takes to train, we chose to search for an optimal number of estimators below 1000. After running GridSearchCV, we found that the optimal number of trees is 600. \n",
    "\n",
    "We also examined the feature importances from the Random Forest model and compared them to that of our Decision Tree model. The feature importance of Elevation was reduced from approximately 0.55 to 0.26 and we saw that soil types that previously had no importance gained some in this model. Perhaps, this suggests that while Elevation is important, it is overemphasized in our Decision Tree model. Additionally, the importance of Wilderness_Area4 rose to 0.07 whereas in the Decision Tree Model, its importance was less than 0.001.\n",
    "\n",
    "### Random Forest: Optimizing for max_depth\n",
    "\n",
    "Given the results of our parameter optimization for Decision Trees, we chose to focus on optimizing for max_depth for our Random Forest model. Having a lower max_depth may also help decrease the speed of training given the optimal number of estimators. The optimal max_depth for Random Forest was found to be 35, which is a bit higher than that of the Decision Tree model. The accuracy of the model with max_depth = 35 is 86.18%--only had a slight improvement in accuracy compared to the baseline Random Forest model, which was 86.11%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.74      0.75       216\n",
      "           2       0.78      0.69      0.73       226\n",
      "           3       0.87      0.83      0.85       203\n",
      "           4       0.92      0.98      0.95       243\n",
      "           5       0.87      0.97      0.92       198\n",
      "           6       0.86      0.85      0.86       222\n",
      "           7       0.94      0.97      0.95       204\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1512\n",
      "   macro avg       0.86      0.86      0.86      1512\n",
      "weighted avg       0.86      0.86      0.86      1512\n",
      "\n",
      "[[160  39   0   0   6   0  11]\n",
      " [ 44 156   1   0  18   5   2]\n",
      " [  0   0 168  11   3  21   0]\n",
      " [  0   0   2 238   0   3   0]\n",
      " [  0   2   1   0 193   2   0]\n",
      " [  0   2  21   9   1 189   0]\n",
      " [  6   0   0   0   0   0 198]]\n",
      "\n",
      "accuracy: 0.8611111111111112\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>0.262381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>0.088981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area4</th>\n",
       "      <td>0.078875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>0.064422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>0.049385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0.043686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <td>0.041909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>0.039704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <td>0.036511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>0.036418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>0.030812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area1</th>\n",
       "      <td>0.029382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <td>0.026133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type10</th>\n",
       "      <td>0.025632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type38</th>\n",
       "      <td>0.017212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type39</th>\n",
       "      <td>0.016430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type3</th>\n",
       "      <td>0.015170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type4</th>\n",
       "      <td>0.012071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type40</th>\n",
       "      <td>0.008490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type30</th>\n",
       "      <td>0.007071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type29</th>\n",
       "      <td>0.006430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type2</th>\n",
       "      <td>0.006361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type13</th>\n",
       "      <td>0.005692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type17</th>\n",
       "      <td>0.005355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type23</th>\n",
       "      <td>0.005036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type32</th>\n",
       "      <td>0.004890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <td>0.004750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type22</th>\n",
       "      <td>0.004287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type33</th>\n",
       "      <td>0.003701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type11</th>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type12</th>\n",
       "      <td>0.003208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type6</th>\n",
       "      <td>0.002867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type31</th>\n",
       "      <td>0.002228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type24</th>\n",
       "      <td>0.001988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type35</th>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type20</th>\n",
       "      <td>0.001383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type1</th>\n",
       "      <td>0.001343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type5</th>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type16</th>\n",
       "      <td>0.000794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type18</th>\n",
       "      <td>0.000728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type14</th>\n",
       "      <td>0.000613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type37</th>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type26</th>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type19</th>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type34</th>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type21</th>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type27</th>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type28</th>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type36</th>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type9</th>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type25</th>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type15</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    importance\n",
       "Elevation                             0.262381\n",
       "Horizontal_Distance_To_Roadways       0.088981\n",
       "Wilderness_Area4                      0.078875\n",
       "Horizontal_Distance_To_Fire_Points    0.064422\n",
       "Horizontal_Distance_To_Hydrology      0.049385\n",
       "Vertical_Distance_To_Hydrology        0.043686\n",
       "Hillshade_9am                         0.041909\n",
       "Aspect                                0.039704\n",
       "Hillshade_3pm                         0.036511\n",
       "Hillshade_Noon                        0.036418\n",
       "Slope                                 0.030812\n",
       "Wilderness_Area1                      0.029382\n",
       "Wilderness_Area3                      0.026133\n",
       "Soil_Type10                           0.025632\n",
       "Soil_Type38                           0.017212\n",
       "Soil_Type39                           0.016430\n",
       "Soil_Type3                            0.015170\n",
       "Soil_Type4                            0.012071\n",
       "Soil_Type40                           0.008490\n",
       "Soil_Type30                           0.007071\n",
       "Soil_Type29                           0.006430\n",
       "Soil_Type2                            0.006361\n",
       "Soil_Type13                           0.005692\n",
       "Soil_Type17                           0.005355\n",
       "Soil_Type23                           0.005036\n",
       "Soil_Type32                           0.004890\n",
       "Wilderness_Area2                      0.004750\n",
       "Soil_Type22                           0.004287\n",
       "Soil_Type33                           0.003701\n",
       "Soil_Type11                           0.003300\n",
       "Soil_Type12                           0.003208\n",
       "Soil_Type6                            0.002867\n",
       "Soil_Type31                           0.002228\n",
       "Soil_Type24                           0.001988\n",
       "Soil_Type35                           0.001681\n",
       "Soil_Type20                           0.001383\n",
       "Soil_Type1                            0.001343\n",
       "Soil_Type5                            0.000986\n",
       "Soil_Type16                           0.000794\n",
       "Soil_Type18                           0.000728\n",
       "Soil_Type14                           0.000613\n",
       "Soil_Type37                           0.000382\n",
       "Soil_Type26                           0.000375\n",
       "Soil_Type19                           0.000273\n",
       "Soil_Type34                           0.000184\n",
       "Soil_Type21                           0.000138\n",
       "Soil_Type27                           0.000116\n",
       "Soil_Type28                           0.000082\n",
       "Soil_Type36                           0.000072\n",
       "Soil_Type9                            0.000070\n",
       "Soil_Type25                           0.000014\n",
       "Soil_Type7                            0.000000\n",
       "Soil_Type8                            0.000000\n",
       "Soil_Type15                           0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: gridsearch can take 10-15 mins to run\n",
    "#rfpl = Pipeline([('classifier', RandomForestClassifier(criterion = 'entropy', random_state = 0))])\n",
    "\n",
    "#param_grid = dict(classifier__n_estimators = [n for n in range(100, 1000, 100)])\n",
    "\n",
    "#rfgs = GridSearchCV(rfpl, param_grid, iid = True, refit = True, cv=5, return_train_score=True).fit(dt_train, train_labels)\n",
    "#print(rfgs.best_params_)\n",
    "\n",
    "rfc1 = RandomForestClassifier(n_estimators = 600, criterion = 'entropy', random_state = 0)\n",
    "rf_accuracies.append(model_performance(rfc1, dt_train, train_labels, dt_dev, dev_labels))\n",
    "rf_experiments.append('Random Forest n_estimators = 600')\n",
    "importance_table(rfc1, dt_train, sort = True)\n",
    "\n",
    "# gridsearch can take 7-10 mins to run\n",
    "#rfpl = Pipeline([('classifier', rfc1)])\n",
    "#param_grid = dict(classifier__max_depth = [n for n in range(10, 55, 5)])\n",
    "\n",
    "#rfgs2 = GridSearchCV(rfpl, param_grid, iid = True, refit = True, cv=5, return_train_score=True).fit(dt_train, train_labels)\n",
    "#print(rfgs2.best_params_)\n",
    "\n",
    "rfc2 = RandomForestClassifier(n_estimators = 600, max_depth = 35, criterion = 'entropy', random_state = 0)\n",
    "rf_accuracies.append(model_performance(rfc2, dt_train, train_labels, dt_dev, dev_labels))\n",
    "rf_experiments.append('Random Forest n_estimators = 600, max_depth = 35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.74      0.75       216\n",
      "           2       0.79      0.69      0.74       226\n",
      "           3       0.87      0.83      0.85       203\n",
      "           4       0.92      0.98      0.95       243\n",
      "           5       0.87      0.97      0.92       198\n",
      "           6       0.86      0.86      0.86       222\n",
      "           7       0.94      0.97      0.95       204\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1512\n",
      "   macro avg       0.86      0.86      0.86      1512\n",
      "weighted avg       0.86      0.86      0.86      1512\n",
      "\n",
      "[[160  39   0   0   6   0  11]\n",
      " [ 44 156   1   0  18   5   2]\n",
      " [  0   0 168  11   3  21   0]\n",
      " [  0   0   2 238   0   3   0]\n",
      " [  0   2   1   0 193   2   0]\n",
      " [  0   1  21   9   1 190   0]\n",
      " [  6   0   0   0   0   0 198]]\n",
      "\n",
      "accuracy: 0.8617724867724867\n"
     ]
    }
   ],
   "source": [
    "# gridsearch can take 7-10 mins to run\n",
    "#rfpl = Pipeline([('classifier', rfc1)])\n",
    "#param_grid = dict(classifier__max_depth = [n for n in range(10, 55, 5)])\n",
    "\n",
    "#rfgs2 = GridSearchCV(rfpl, param_grid, iid = True, refit = True, cv=5, return_train_score=True).fit(dt_train, train_labels)\n",
    "#print(rfgs2.best_params_)\n",
    "\n",
    "rfc2 = RandomForestClassifier(n_estimators = 600, max_depth = 35, criterion = 'entropy', random_state = 0)\n",
    "rf_accuracies.append(model_performance(rfc2, dt_train, train_labels, dt_dev, dev_labels))\n",
    "rf_experiments.append('Random Forest n_estimators = 600, max_depth = 35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FINAL RESULTS\n",
    "\n",
    "# Best Decision Tree\n",
    "\n",
    "best_dt = DecisionTreeClassifier(criterion = 'entropy', max_depth = 24, random_state = 0)\n",
    "\n",
    "# Best Random Forest\n",
    "\n",
    "best_rf = RandomForestClassifier(criterion = 'entropy', n_estimators = 600, max_depth = 35,  random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "- Summary\n",
    "    - Dropping Slope and Aspect\n",
    "        - Reasoning: Hillshade is calculated using Slope and Aspect so removing Slope and Aspect may make our model more parsimonious without information loss. Additionally, of the continuous variables, Slope and Aspect were among those with the least feature importance based on our best Decision Tree and Random Forest models.\n",
    "    - Dropping soil types that had little to no feature importance\n",
    "        - Reasoning: In our best Decision Tree model, 9 soil types had less than 0.0001 feature importance with 7 having no importance. In our best Random Forest model, 7 soil types had less than 0.0001 feature importance with 3 having no importance.\n",
    "    - Dropping Slope, Aspect, and Unimportant Soil Types\n",
    "        - This led us to examine how these models would perform if all of these variables were excluded, reducing the dataset to 43 columns. We did not see much improvement for the Decision Tree model, but the Random Forest model's accuracy increased to 87.07% and the F-1 scores increased for cover types 1, 2, 3, 6, and 7, some of which are the most confused in other models.\n",
    "\n",
    "### Feature Selection: Dropping Slope and Aspect in Dataset\n",
    "\n",
    "The Decision Tree model (optimized for max_depth) trained on the dataset excluding slope and aspect had an accuracy of 79.43%, which is not much smaller than that of the Decision Model trained on the full dataset. However, in comparing the confusion matrices, the model trained with the smaller dataset confused the classification of cover types 1 and 2 more than the model with the full dataset. However, in terms of the Random Forest model (optimized for max_depth), we found slightly better accuracy at 86.84% training with this smaller dataset. Below, we highlight the results from the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.75      0.76       216\n",
      "           2       0.78      0.70      0.74       226\n",
      "           3       0.88      0.84      0.86       203\n",
      "           4       0.93      0.98      0.96       243\n",
      "           5       0.89      0.97      0.93       198\n",
      "           6       0.86      0.86      0.86       222\n",
      "           7       0.95      0.98      0.96       204\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      1512\n",
      "   macro avg       0.87      0.87      0.87      1512\n",
      "weighted avg       0.87      0.87      0.87      1512\n",
      "\n",
      "[[161  42   0   0   5   0   8]\n",
      " [ 42 159   1   0  15   6   3]\n",
      " [  0   0 170  10   2  21   0]\n",
      " [  0   0   1 239   0   3   0]\n",
      " [  0   2   1   0 193   2   0]\n",
      " [  0   1  20   8   1 192   0]\n",
      " [  5   0   0   0   0   0 199]]\n",
      "\n",
      "accuracy: 0.8683862433862434\n"
     ]
    }
   ],
   "source": [
    "# removing from train\n",
    "drop_col1 = ['Slope', 'Aspect']\n",
    "dt_train2 = dt_train.drop(drop_col1, axis = 1)\n",
    "dt_dev2 = dt_dev.drop(drop_col1, axis = 1)\n",
    "\n",
    "# using GridSearch, we found max_depth = 20 to be optimal\n",
    "dt_accuracies.append(model_performance(best_dt, dt_train2, train_labels, dt_dev2, dev_labels, metrics = False))\n",
    "dt_experiments.append('Feature Selection: No Slope, Aspect')\n",
    "# using GridSearch, we found max_depth = 40 to be optimal\n",
    "rf_accuracies.append(model_performance(best_rf, dt_train2, train_labels, dt_dev2, dev_labels))\n",
    "rf_experiments.append('Feature Selection: No Slope, Aspect')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: Dropping the soil types that have little to no importance\n",
    "\n",
    "In examining feature importances of the Decision Tee and Random Forest models, we saw that some soil types continued to show little or no importance. We examined the effect of dropping those specific soil types and retraining on this smaller dataset and saw improvements for both models. For the Decision Tree model, the accuracy increased to 80.29% and for the Random Forest model, the accuracy increased to 86.04%. Below, we highlight the results for retraining on the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.73      0.75       216\n",
      "           2       0.78      0.69      0.73       226\n",
      "           3       0.87      0.82      0.85       203\n",
      "           4       0.92      0.98      0.95       243\n",
      "           5       0.88      0.97      0.92       198\n",
      "           6       0.86      0.86      0.86       222\n",
      "           7       0.94      0.97      0.95       204\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1512\n",
      "   macro avg       0.86      0.86      0.86      1512\n",
      "weighted avg       0.86      0.86      0.86      1512\n",
      "\n",
      "[[158  42   0   0   5   0  11]\n",
      " [ 43 157   1   0  18   5   2]\n",
      " [  0   0 167  11   3  22   0]\n",
      " [  0   0   3 237   0   3   0]\n",
      " [  0   2   1   0 193   2   0]\n",
      " [  0   1  20   9   1 191   0]\n",
      " [  6   0   0   0   0   0 198]]\n",
      "\n",
      "accuracy: 0.8604497354497355\n"
     ]
    }
   ],
   "source": [
    "# this list is from the feature importances table from the best random forest\n",
    "rf_table = importance_table(best_rf.fit(dt_train, train_labels), dt_train, sort = True)\n",
    "drop_col2 = rf_table.index[rf_table['importance'] < 0.0001].tolist()\n",
    "\n",
    "dt_train3 = dt_train.drop(drop_col2, axis = 1)\n",
    "dt_dev3 = dt_dev.drop(drop_col2, axis = 1)\n",
    "\n",
    "dt_accuracies.append(model_performance(best_dt, dt_train3, train_labels, dt_dev3, dev_labels, metrics = False))\n",
    "dt_experiments.append('Feature Selection: No Unimporant Soil Types')\n",
    "rf_accuracies.append(model_performance(best_rf, dt_train3, train_labels, dt_dev3, dev_labels))\n",
    "rf_experiments.append('Feature Selection: No Unimporant Soil Types')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: Dropping Slope, Aspect, & Unimportant Soil Types\n",
    "\n",
    "Based on the results of the previous experiments, we examined the impact of removing the combination of these columns from the dataset and retraining both types of models. This resulted in 79.43% accuracy for the Decision Tree model. On the other hand, we saw an increase in accuracy for the Random Forest model at 87.03%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.75      0.77       216\n",
      "           2       0.79      0.70      0.74       226\n",
      "           3       0.88      0.84      0.86       203\n",
      "           4       0.93      0.98      0.95       243\n",
      "           5       0.89      0.97      0.93       198\n",
      "           6       0.86      0.86      0.86       222\n",
      "           7       0.94      0.98      0.96       204\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      1512\n",
      "   macro avg       0.87      0.87      0.87      1512\n",
      "weighted avg       0.87      0.87      0.87      1512\n",
      "\n",
      "[[163  39   0   0   5   0   9]\n",
      " [ 42 159   2   0  16   4   3]\n",
      " [  0   0 171  10   1  21   0]\n",
      " [  0   0   1 239   0   3   0]\n",
      " [  0   2   1   0 193   2   0]\n",
      " [  0   1  19   9   1 192   0]\n",
      " [  5   0   0   0   0   0 199]]\n",
      "\n",
      "accuracy: 0.8703703703703703\n"
     ]
    }
   ],
   "source": [
    "drop_col3 = drop_col1 + drop_col2\n",
    "dt_train4 = dt_train.drop(drop_col3, axis = 1)\n",
    "dt_dev4 = dt_dev.drop(drop_col3, axis = 1)\n",
    "\n",
    "dt_accuracies.append(model_performance(best_dt, dt_train4, train_labels, dt_dev4, dev_labels, metrics = False))\n",
    "dt_experiments.append('Feature Selection: No Slope, Aspect, & Unimportant Soil Types')\n",
    "rf_accuracies.append(model_performance(best_rf, dt_train4, train_labels, dt_dev4, dev_labels))\n",
    "rf_experiments.append('Feature Selection: No Slope, Aspect, & Unimportant Soil Types')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: New Soil Type Features\n",
    "\n",
    "By far, the soil types contribute the most to the high dimensionality of the train dataset since there are 40 types. From experimenting with feature selection, we know that there is some information value to the soil types, but there may be a way to reduce the dimensions without loss of information. First, we ran our best Random Forest model on just the soil types as a way to prioritize the importance of the soil types. \n",
    "\n",
    "The original problem description also came with information on each soil type. We did a basic analysis of the words/terms in these descriptions to create new one-hot encoded features such as stony, rubbly, Leighcan, Catamount, complex, etc. These denoted soil qualities and common families they share. As we have seen with other models, some soil types have little to no importance, so we excluded these from the analysis in further efforts to keep the number of dimensions lower. Through this, we were able to describe the soil types with 33 columns compared to the original 40. We also tested a version of new features created from just the most important soil types and reduced the columns to 23 in that case. Both versions had comparable performance to the original dataset performing slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets with just the soil types\n",
    "dt_train_justsoil = dt_train.drop(list(train_data.columns[:14]), axis = 1)\n",
    "dt_dev_justsoil = dt_dev.drop(list(dev_data.columns[:14]), axis = 1)\n",
    "\n",
    "best_rf_soils = RandomForestClassifier(n_estimators = 600, max_depth = 35, criterion = 'entropy', random_state = 0).fit(dt_train_justsoil, train_labels)\n",
    "# get the feature importance of the soil types\n",
    "rf_importance_soil = importance_table(best_rf_soils, dt_train_justsoil, sort = True)\n",
    "# we will use the mean of the feature importance to set the threshold of which soil types are important\n",
    "importance_threshold = np.mean(rf_importance_soil['importance'])\n",
    "\n",
    "# get the unimportant soil types\n",
    "remove_soils = rf_importance_soil.index[rf_importance_soil['importance'] < 0.001].tolist()\n",
    "remove_soil_ind = []\n",
    "# get the indices for these soil types\n",
    "for soil in remove_soils:\n",
    "    remove_soil_ind.append(int(soil.split('Soil_Type')[1]) - 1)\n",
    "\n",
    "# get the most important soil types\n",
    "priority_soils = rf_importance_soil.index[rf_importance_soil['importance'] > importance_threshold].tolist()\n",
    "priority_soil_ind = []\n",
    "# get the indices for these soil types\n",
    "for soil in priority_soils:\n",
    "    priority_soil_ind.append(int(soil.split('Soil_Type')[1]) - 1)\n",
    "\n",
    "# read in the soil type info\n",
    "soils_analysis = pd.read_csv('soil_types.csv', header = None)\n",
    "# drop the unimportant soil types so they won't be included in the description analysis\n",
    "soils_analysis_all = soils_analysis.drop(remove_soil_ind, axis = 0)\n",
    "# get only the most important soil types\n",
    "soils_analysis_priority = soils_analysis.iloc[priority_soil_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with New Soil Features from All Soil Types:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.71      0.73       216\n",
      "           2       0.76      0.70      0.73       226\n",
      "           3       0.87      0.85      0.86       203\n",
      "           4       0.93      0.98      0.95       243\n",
      "           5       0.89      0.97      0.93       198\n",
      "           6       0.87      0.86      0.87       222\n",
      "           7       0.92      0.97      0.94       204\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1512\n",
      "   macro avg       0.86      0.86      0.86      1512\n",
      "weighted avg       0.86      0.86      0.86      1512\n",
      "\n",
      "[[154  45   0   0   4   0  13]\n",
      " [ 44 158   1   0  16   4   3]\n",
      " [  0   0 172   9   3  19   0]\n",
      " [  0   0   3 237   0   3   0]\n",
      " [  0   2   1   0 193   2   0]\n",
      " [  0   2  20   9   0 191   0]\n",
      " [  7   0   0   0   0   0 197]]\n",
      "\n",
      "accuracy: 0.8611111111111112\n",
      "Random Forest with New Soil Features from Most Important Soil Types:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.72      0.74       216\n",
      "           2       0.77      0.71      0.74       226\n",
      "           3       0.88      0.84      0.86       203\n",
      "           4       0.93      0.98      0.96       243\n",
      "           5       0.89      0.97      0.93       198\n",
      "           6       0.86      0.86      0.86       222\n",
      "           7       0.92      0.96      0.94       204\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1512\n",
      "   macro avg       0.86      0.86      0.86      1512\n",
      "weighted avg       0.86      0.86      0.86      1512\n",
      "\n",
      "[[155  44   0   0   4   0  13]\n",
      " [ 42 160   0   0  16   5   3]\n",
      " [  0   0 170   9   4  20   0]\n",
      " [  0   0   2 238   0   3   0]\n",
      " [  0   2   1   0 193   2   0]\n",
      " [  0   2  21   8   0 191   0]\n",
      " [  8   0   0   0   0   0 196]]\n",
      "\n",
      "accuracy: 0.8617724867724867\n"
     ]
    }
   ],
   "source": [
    "def get_terms(soil_desc):\n",
    "    \"\"\" Takes in list of soil descriptions and builds a dict of word and word count \"\"\"\n",
    "    terms_dict = {}\n",
    "\n",
    "    for soil in soil_desc[0]:\n",
    "        soil = re.sub(r'[^\\w\\s]','', soil)\n",
    "        words = soil.split()\n",
    "\n",
    "        for word in words:\n",
    "            if word in [str(n) for n in range(1, 41)]:\n",
    "                continue\n",
    "            elif word in terms_dict:\n",
    "                terms_dict[word] += 1\n",
    "            else:\n",
    "                terms_dict[word] = 1\n",
    "    \n",
    "    return terms_dict\n",
    "\n",
    "def filter_terms(terms_dict):\n",
    "    \"\"\" Takes in the terms dictionary and remove unnecessary words and add in common two word terms \"\"\"\n",
    "    \n",
    "    terms = list(terms_dict.keys())\n",
    "    remove_terms = ['family', 'Rock', 'outcrop', 'extremely', 'families', 'very', 'land', 'till', 'substratum']\n",
    "\n",
    "    for term in remove_terms:\n",
    "        try:\n",
    "            terms.remove(term)\n",
    "        except:\n",
    "            continue\n",
    "    # add back in two word terms\n",
    "    terms = terms + ['Rock land', 'Rock outcrop', 'till substratum']\n",
    "    \n",
    "    return terms\n",
    "\n",
    "def new_soil_feats(terms, soils_df, train_data, dev_data):\n",
    "    \n",
    "    \"\"\" Creates new dataset with added soil features \"\"\"\n",
    "    soils_df['Soil_Cat'] = soils_df[0].apply(lambda s: int(re.findall(r'\\d+', s)[0]))\n",
    "    soils_df.set_index('Soil_Cat', inplace = True)\n",
    "    \n",
    "    for term in terms:\n",
    "\n",
    "        soils_df[term] = soils_df[0].apply(lambda s: int(len(re.findall(term, s)) == 1))\n",
    "\n",
    "    # deep copy the train_data and dev_data\n",
    "    fe_train = copy.deepcopy(train_data)\n",
    "    fe_dev = copy.deepcopy(dev_data)\n",
    "    \n",
    "    # set up soil_cat for the merge\n",
    "    fe_train['Soil_Cat'] = 0\n",
    "    soil_names = ['Soil_Type' + str(i) for i in range(1, 41)]\n",
    "    for i, name in enumerate(soil_names, 1):\n",
    "        fe_train.loc[fe_train[name] == 1, 'Soil_Cat'] = i\n",
    "\n",
    "    fe_dev['Soil_Cat'] = 0\n",
    "    soil_names = ['Soil_Type' + str(i) for i in range(1, 41)]\n",
    "    for i, name in enumerate(soil_names, 1):\n",
    "        fe_dev.loc[fe_dev[name] == 1, 'Soil_Cat'] = i\n",
    "    \n",
    "    fe_train.drop(list(fe_train.columns[14:54]), axis = 1, inplace = True)\n",
    "    fe_dev.drop(list(fe_dev.columns[14:54]), axis = 1, inplace = True)\n",
    "    \n",
    "    # create copy of train_dataset with these additional soil type dummy variables\n",
    "    fe_train_sg = fe_train.merge(soils_df.drop(0, axis = 1), right_index = True, left_on = 'Soil_Cat', how='left')\n",
    "    # take out unnecessary columns\n",
    "    fe_train_sg.drop('Soil_Cat', axis = 1, inplace = True)\n",
    "\n",
    "    fe_dev_sg = fe_dev.merge(soils_df.drop(0, axis = 1), right_index = True, left_on = 'Soil_Cat', how='left')\n",
    "    fe_dev_sg.drop('Soil_Cat', axis = 1, inplace = True)\n",
    "    \n",
    "    return fe_train_sg, fe_dev_sg\n",
    "\n",
    "# deep copy the soils analysis dataframe\n",
    "soils_df_all = copy.deepcopy(soils_analysis)\n",
    "soils_df_priority = copy.deepcopy(soils_analysis)\n",
    "\n",
    "all_terms_dict = get_terms(soils_analysis_all)\n",
    "priority_terms_dict = get_terms(soils_analysis_priority)\n",
    "all_terms = filter_terms(all_terms_dict)\n",
    "priority_terms = filter_terms(priority_terms_dict)\n",
    "\n",
    "fe_train_all, fe_dev_all = new_soil_feats(all_terms, soils_df_all, dt_train, dt_dev)\n",
    "fe_train_priority, fe_dev_priority= new_soil_feats(priority_terms, soils_df_priority, dt_train, dt_dev)\n",
    "\n",
    "# gridsearch found that 900 estimators was optimal for both datasets\n",
    "best_rf_fe = RandomForestClassifier(n_estimators = 900, criterion = 'entropy', random_state = 0)\n",
    "\n",
    "print(\"Random Forest with New Soil Features from All Soil Types:\")\n",
    "rf_accuracies.append(model_performance(best_rf_fe, fe_train_all, train_labels, fe_dev_all, dev_labels))\n",
    "rf_experiments.append('Feature Engineering: New Soil Features From All')\n",
    "print(\"Random Forest with New Soil Features from Most Important Soil Types:\")\n",
    "rf_accuracies.append(model_performance(best_rf_fe, fe_train_priority, train_labels, fe_dev_priority, dev_labels))\n",
    "rf_experiments.append('Feature Engineering: New Soil Features From Important Soil Types')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree & Random Forest Final Result\n",
    "\n",
    "Our experiments have shown that Random Forest outperforms Decision Tree for this problem, which is not unexpected given that Random Forest is a meta estimator that uses many Decision Trees. After various parameter optimization, feature selection, and feature engineering experiments, we find that the optimized Random Forest model with 600 trees and max_depth = 35 in combination with datasets without Slope, Aspect, and unimportant soil types yield the best results with the development data. \n",
    "\n",
    "When predicting using the best models with this feature selection on the test data, we saw that this resulted in an increase of approximately 2-3% in accuracy for both our best Decision Tree and Random Forest models. Please see the tables below for a summary of our experiments and final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_final = dt_train.drop(drop_col3, axis = 1)\n",
    "dt_dev_final = dt_dev.drop(drop_col3, axis = 1)\n",
    "dt_test_final = dt_test.drop(drop_col3, axis = 1)\n",
    "\n",
    "dt_accuracies.append(model_performance(best_dt, dt_train, train_labels, dt_test, test_labels, metrics = False))\n",
    "dt_experiments.append('Best Model with Untransformed Test Data')\n",
    "dt_accuracies.append(model_performance(best_dt, dt_train_final, train_labels, dt_test_final, test_labels, metrics = False))\n",
    "dt_experiments.append('Best Model with Transformed Test Data')\n",
    "\n",
    "rf_accuracies.append(model_performance(best_rf, dt_train, train_labels, dt_test, test_labels, metrics = False))\n",
    "rf_experiments.append('Best Model with Untransformed Test Data')\n",
    "rf_accuracies.append(model_performance(best_rf, dt_train_final, train_labels, dt_test_final, test_labels, metrics = False))\n",
    "rf_experiments.append('Best Model with Transformed Test Data')\n",
    "\n",
    "dt_results = pd.DataFrame({'Experiment':dt_experiments, 'Accuracy':dt_accuracies})\n",
    "dt_results.set_index('Experiment', inplace = True)\n",
    "\n",
    "rf_results = pd.DataFrame({'Experiment':rf_experiments, 'Accuracy':rf_accuracies})\n",
    "rf_results.set_index('Experiment', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Modeling Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Basic Decision Tree</th>\n",
       "      <td>0.792328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree with max_depth = 24</th>\n",
       "      <td>0.796958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree with max_features = 40</th>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree with min_samples_split = 0.001</th>\n",
       "      <td>0.789021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree with min_samples_leaf = 0.001</th>\n",
       "      <td>0.768519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Selection: No Slope, Aspect</th>\n",
       "      <td>0.787698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Selection: No Unimporant Soil Types</th>\n",
       "      <td>0.796958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Selection: No Slope, Aspect, &amp; Unimportant Soil Types</th>\n",
       "      <td>0.794974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Model with Untransformed Test Data</th>\n",
       "      <td>0.807540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Model with Transformed Test Data</th>\n",
       "      <td>0.828704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy\n",
       "Experiment                                                  \n",
       "Basic Decision Tree                                 0.792328\n",
       "Decision Tree with max_depth = 24                   0.796958\n",
       "Decision Tree with max_features = 40                0.795635\n",
       "Decision Tree with min_samples_split = 0.001        0.789021\n",
       "Decision Tree with min_samples_leaf = 0.001         0.768519\n",
       "Feature Selection: No Slope, Aspect                 0.787698\n",
       "Feature Selection: No Unimporant Soil Types         0.796958\n",
       "Feature Selection: No Slope, Aspect, & Unimport...  0.794974\n",
       "Best Model with Untransformed Test Data             0.807540\n",
       "Best Model with Transformed Test Data               0.828704"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Decision Tree Modeling Summary\")\n",
    "dt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Modeling Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest n_estimators = 600</th>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest n_estimators = 600, max_depth = 35</th>\n",
       "      <td>0.861772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Selection: No Slope, Aspect</th>\n",
       "      <td>0.868386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Selection: No Unimporant Soil Types</th>\n",
       "      <td>0.860450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Selection: No Slope, Aspect, &amp; Unimportant Soil Types</th>\n",
       "      <td>0.870370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Engineering: New Soil Features From All</th>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Engineering: New Soil Features From Important Soil Types</th>\n",
       "      <td>0.861772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Model with Untransformed Test Data</th>\n",
       "      <td>0.876984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Model with Transformed Test Data</th>\n",
       "      <td>0.892196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy\n",
       "Experiment                                                  \n",
       "Random Forest n_estimators = 600                    0.861111\n",
       "Random Forest n_estimators = 600, max_depth = 35    0.861772\n",
       "Feature Selection: No Slope, Aspect                 0.868386\n",
       "Feature Selection: No Unimporant Soil Types         0.860450\n",
       "Feature Selection: No Slope, Aspect, & Unimport...  0.870370\n",
       "Feature Engineering: New Soil Features From All     0.861111\n",
       "Feature Engineering: New Soil Features From Imp...  0.861772\n",
       "Best Model with Untransformed Test Data             0.876984\n",
       "Best Model with Transformed Test Data               0.892196"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Random Forest Modeling Summary\")\n",
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_optimzer(best_model, estimators, learning_rates, transformed_train, transformed_dev):\n",
    "    \n",
    "    #FUNCTION ARGUMENTS:\n",
    "    #best_model - best version of the model to boost\n",
    "    #estimators - a list of integers to input the n_estimators argument\n",
    "    #learning_rates - list of learning rates to input to the learning_rate argument\n",
    "    #trainsformed_train - the version of train_data post feature engineering used in the best_model\n",
    "    #trainsformed_dev - the version of dev_data post feature engineering used in the best_model \n",
    "    \n",
    "    results = []\n",
    "    for n in estimators:\n",
    "        for lr in learning_rates:\n",
    "            abc = AdaBoostClassifier(base_estimator=best_model, n_estimators=n, learning_rate=lr, random_state = 0)\n",
    "            abc.fit(transformed_train, train_labels)\n",
    "            accuracy = abc.score(transformed_dev, dev_labels)\n",
    "            \n",
    "            results.append([n, lr, accuracy])\n",
    "            \n",
    "    results_t = pd.DataFrame(results)         \n",
    "    results_t.columns = [\"Maximum Number of Estimators\", \"Learning Rates\", \"Accuracy for Adaboost\"]\n",
    "    return results_t.sort_values(by = 'Accuracy for Adaboost', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maximum Number of Estimators</th>\n",
       "      <th>Learning Rates</th>\n",
       "      <th>Accuracy for Adaboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.806878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.806878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.806878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>400</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.806878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.802910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.802910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.802910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.802910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.798280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.798280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>300</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.798280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>400</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.798280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.784392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.784392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>300</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.784392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>400</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.784392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Maximum Number of Estimators  Learning Rates  Accuracy for Adaboost\n",
       "2                            100           0.100               0.806878\n",
       "6                            200           0.100               0.806878\n",
       "10                           300           0.100               0.806878\n",
       "14                           400           0.100               0.806878\n",
       "0                            100           0.001               0.802910\n",
       "4                            200           0.001               0.802910\n",
       "8                            300           0.001               0.802910\n",
       "12                           400           0.001               0.802910\n",
       "1                            100           0.010               0.798280\n",
       "5                            200           0.010               0.798280\n",
       "9                            300           0.010               0.798280\n",
       "13                           400           0.010               0.798280\n",
       "3                            100           1.000               0.784392\n",
       "7                            200           1.000               0.784392\n",
       "11                           300           1.000               0.784392\n",
       "15                           400           1.000               0.784392"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1, 1]\n",
    "estimators = [n for n in range(100, 500, 100)]\n",
    "\n",
    "adaboost_optimzer(best_dt, estimators, learning_rates, dt_train, dt_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maximum Number of Estimators</th>\n",
       "      <th>Learning Rates</th>\n",
       "      <th>Accuracy for Adaboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>300</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>300</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>400</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>400</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>400</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.795635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Maximum Number of Estimators  Learning Rates  Accuracy for Adaboost\n",
       "0                            100           0.001               0.795635\n",
       "1                            100           0.010               0.795635\n",
       "2                            100           0.100               0.795635\n",
       "3                            100           1.000               0.795635\n",
       "4                            200           0.001               0.795635\n",
       "5                            200           0.010               0.795635\n",
       "6                            200           0.100               0.795635\n",
       "7                            200           1.000               0.795635\n",
       "8                            300           0.001               0.795635\n",
       "9                            300           0.010               0.795635\n",
       "10                           300           0.100               0.795635\n",
       "11                           300           1.000               0.795635\n",
       "12                           400           0.001               0.795635\n",
       "13                           400           0.010               0.795635\n",
       "14                           400           0.100               0.795635\n",
       "15                           400           1.000               0.795635"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1, 1]\n",
    "estimators = [n for n in range(100, 500, 100)]\n",
    "\n",
    "adaboost_optimzer(best_dt, estimators, learning_rates, dt_train_final, dt_dev_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting Classifier: Multi-Model Ensemble\n",
    "\n",
    "Utilizing our two best models, SVM and Random Forest, we created a Voting Classifier model with soft voting based on probabilities. Surprisingly, the Voting model was much more accurate using unscaled data, which is necessary for SVM. As we've seen in our EDA and in other models, Elevation had a lot of importance in terms of prediction. Since Elevation has the largest range among the unscaled features, it is likely overemphasized in the SVM model and may contribute to the increased accuracy in this case. The model achieved an accuracy of 89.08% on the unscaled development dataset in conjunction with our feature selection method of excluding Slope, Aspect, and unimportant soil types.\n",
    "\n",
    "For the unscaled test dataset, the Voting Classifier model achieved 88.82% accuracy, which was lower than that of the single Random Forest model. In particular, it had more misclassifications of cover type 1. However, this model had better F-1 scores for cover types 5 and 6 and better accuracy for cover types 2 and 3. In future iterations, this ensemble method may be strengthened with the inclusion of other well-calibrated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma = 'scale', kernel = 'rbf', C = 1.0, probability = True, random_state = 0)\n",
    "rfc = RandomForestClassifier(criterion = 'entropy', n_estimators = 600, max_depth = 35,  random_state = 0)\n",
    "estimators = [('svm', svm), ('rf', rfc)]\n",
    "\n",
    "voting = VotingClassifier(estimators, voting = 'soft')\n",
    "print(\"SVM & Random Forest Ensemble with dev_data\")\n",
    "model_performance(voting, dt_train_final, train_labels, dt_dev_final, dev_labels)\n",
    "print(\"SVM & Random Forest Ensemble with test_data\")\n",
    "model_performance(voting, dt_train_final, train_labels, dt_test_final, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
